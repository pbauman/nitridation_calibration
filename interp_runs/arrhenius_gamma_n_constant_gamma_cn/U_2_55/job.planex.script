#!/bin/sh
#SBATCH --clusters=mae
#SBATCH --partition=planex
#SBATCH --account=pi-pbauman
#SBATCH --mem=64000
#SBATCH --time=36:00:00
#SBATCH --nodes=12
#SBATCH --ntasks-per-node=20
#SBATCH --job-name="U_2_55"
#SBATCH --output=run.out
#SBATCH --exclusive
#SBATCH --mail-user=pbauman@buffalo.edu
#SBATCH --mail-type=ALL
##SBATCH --requeue
#Specifies that the job will be requeued after a node failure.
#The default is that the job will not be requeued.

echo "SLURM_JOB_ID="$SLURM_JOB_ID
echo "SLURM_JOB_NODELIST"=$SLURM_JOB_NODELIST
echo "SLURM_NNODES"=$SLURM_NNODES
echo "SLURMTMPDIR="$SLURMTMPDIR

cd $SLURM_SUBMIT_DIR
echo "working directory = "$SLURM_SUBMIT_DIR

ulimit -s unlimited
#

echo "Launch helloworld with srun"
NPROCS=`srun --nodes=${SLURM_NNODES} bash -c 'hostname' |wc -l`
echo NPROCS=$NPROCS
export I_MPI_PMI_LIBRARY=/usr/lib64/libpmi.so
srun -n $NPROCS $NITCAL_DIR/bin/nit_interp ./model.in ./queso.in -ksp_type preonly -pc_type lu -pc_factor_mat_solver_package superlu_dist
#srun -n $NPROCS ../../bin/grins ./backward_facing_step.in -ksp_type gmres -pc_type bjacobi -sub_pc_type lu -sub_pc_factor_mat_solver_package superlu

#
echo "All Done!"
